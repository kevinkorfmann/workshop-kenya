[
  {
    "objectID": "session_1.html",
    "href": "session_1.html",
    "title": "1. Session - MalariaGEN",
    "section": "",
    "text": "The database includes information on the genetic diversity of the parasite, including data on single nucleotide polymorphisms (SNPs) and copy number variations (CNVs). It also provides information on the distribution of drug resistance mutations, which is critical for developing effective malaria treatments.\nIn addition to genomic data, MalariaGen.net also provides access to other types of data, including epidemiological and clinical data. These data are integrated with the genomic data to provide a comprehensive view of the malaria landscape, including information on the distribution of different malaria parasite strains and their associated clinical outcomes.\nOverall, MalariaGen.net is an essential resource for researchers and public health officials working towards the goal of eliminating malaria. By providing open access to comprehensive genomic and epidemiological data, MalariaGen.net is helping to drive advances in our understanding of the biology of the malaria parasite and to inform the development of new and effective malaria control strategies."
  },
  {
    "objectID": "session_1.html#data",
    "href": "session_1.html#data",
    "title": "1. Session - MalariaGEN",
    "section": "Data",
    "text": "Data\nhttps://www.dropbox.com/sh/prelp6g1g369uec/AACruu4uCLf-v0PP1La5Yh_6a?dl=0"
  },
  {
    "objectID": "session_1.html#outline",
    "href": "session_1.html#outline",
    "title": "1. Session - MalariaGEN",
    "section": "Outline",
    "text": "Outline\nWe’ll be focussing on the pathogen P. falciparum.\n\n\n\nAlphonse Laveran was the first to identify the parasite in 1880, and named it Oscillaria malariae.\n\n\n\nExplore datasets available MalariaGEN related to P. falciparum\nWe will be looking specifically at the following resources, short variants (SNPs only) and metadata:\n- 20,864 samples from 33 countries, but we will filter specifically for african countries (Kenya, …)\n- VCF accessable at: ftp://ngs.sanger.ac.uk/production/malaria/Resource/34/Pf7_vcf/ using i.e. FileZilla\n- Filter version will be supplied due to large file sizes > 100 GBs (BCFTools) - Resistance status to drugs, like: Chloroquine, Pyrimethamine, Sulfadoxine, Mefloquine, Artemisinin, Piperaquine\n- Other metadata, i.e. geographic location\nAfter downloading and filtering the data we can load them with the python package scikit-allel. Next, we will filter, based on the samples of our country of interest and build geneologies with tsinfer. Afterwards, we date the inferred geneologies and calculate summary statistics, like genetic diversity and Tajimas D.\n\nTo see more available data sources, of humans, mosquitos or different P. vivax feel free to explore: https://www.malariagen.net/data"
  },
  {
    "objectID": "session_1.html#analysis",
    "href": "session_1.html#analysis",
    "title": "1. Session - MalariaGEN",
    "section": "Analysis",
    "text": "Analysis\nIn the following part of potential analysis path is shown, feel free to follow it and/or modify it.\n\nMetadata\n\n#pip install requests pandas\n\n\n# python package imports\n\nimport os, io, requests\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#data_directory = Path(\"../data\")\n\n\n# Downloading samples information  \nsamples_url = \"https://www.malariagen.net/sites/default/files/Pf7_samples.txt\"\nsamples_metadata = pd.read_csv(io.StringIO(requests.get(samples_url).content.decode('utf-8')), sep=\"\\t\")\nsamples_metadata.head().iloc[:1]\n\n\n\n\n\n  \n    \n      \n      Sample\n      Study\n      Country\n      Admin level 1\n      Country latitude\n      Country longitude\n      Admin level 1 latitude\n      Admin level 1 longitude\n      Year\n      ENA\n      All samples same case\n      Population\n      % callable\n      QC pass\n      Exclusion reason\n      Sample type\n      Sample was in Pf6\n    \n  \n  \n    \n      0\n      FP0008-C\n      1147-PF-MR-CONWAY\n      Mauritania\n      Hodh el Gharbi\n      20.265149\n      -10.337093\n      16.565426\n      -9.832345\n      2014.0\n      ERR1081237\n      FP0008-C\n      AF-W\n      82.16\n      True\n      Analysis_set\n      gDNA\n      True\n    \n  \n\n\n\n\n\nafrican_countries = ['Benin', 'Burkina Faso','Cameroon', 'Gabon' ,'Cameroon', 'Côte d\\'Ivoire','Mozambique', 'Democratic Republic of the Congo','Sudan', 'Ethiopia', 'Gambia', 'Ghana', 'Guinea', 'Kenya', 'Madagascar', 'Malawi', 'Mali', 'Mauritania', 'Nigeria', 'Senegal', 'Tanzania', 'Uganda']\nnon_african_countries = ['Bangladesh', 'Cambodia', 'Colombia', 'India', 'Indonesia', 'Laos', 'Myanmar', 'Papua New Guinea', 'Peru', 'Thailand', 'Venezuela', 'Vietnam']\nafrican_subset = ['Kenya', 'Ethiopia', 'Tanzania', 'Uganda']\n\nNext we identify the sample ids, which we want to explore:\n\n# form sample table above create mask to filter the table to only contain rows of interest\nsamples_metadata_mask = [True if criteria in african_subset else False for criteria in samples_metadata.Country]\nsamples_metadata = samples_metadata[samples_metadata_mask]\n\n# quality control filtering\nsamples_metadata = samples_metadata[samples_metadata[\"QC pass\"]]\n\n# we only look at genomic DNA (gDNA) for now\nsamples_metadata_mask = [True if criteria in [\"gDNA\"] else False for criteria in samples_metadata[\"Sample type\"]]\nsamples_metadata = samples_metadata[samples_metadata_mask]\n\n# reseting tables indices\nsamples_metadata = samples_metadata.reset_index(drop=True)\n\n\nsamples_metadata_kenya = samples_metadata[samples_metadata[\"Country\"] == \"Kenya\"]\n\nprint(f\"Number of gDNA samples in Kenya with QC pass True {samples_metadata_kenya.shape[0]}.\")\n\nNumber of gDNA samples in Kenya with QC pass True 321.\n\n\nSave Kenyan samples ids to txt file:\n\nkenyian_samples = samples_metadata_kenya[\"Sample\"].tolist()\n\n#samples_ids = samples_metadata_kenya.Sample.tolist()\n#with open(data_directory/\"kenyan_sample_ids.txt\", \"a\") as f:\n#    for samples_id in samples_ids:\n#        f.write(samples_id + \"\\n\")"
  },
  {
    "objectID": "session_1.html#what-is-an-gff-file-general-feature-format",
    "href": "session_1.html#what-is-an-gff-file-general-feature-format",
    "title": "1. Session - MalariaGEN",
    "section": "What is an GFF file (General Feature Format)",
    "text": "What is an GFF file (General Feature Format)\nStandardized file format, which contains information where to find what genomic element in the genome.\n\n\n\nGFF"
  },
  {
    "objectID": "session_1.html#gff-file-analysis",
    "href": "session_1.html#gff-file-analysis",
    "title": "1. Session - MalariaGEN",
    "section": "GFF file analysis",
    "text": "GFF file analysis\n\n# path needs to be adapted\ngff_path = Path(\"../../Pfalciparum_replace_Pf3D7_MIT_v3_with_Pf_M76611.gff\")\ngff = pd.read_csv(gff_path, sep=\"\\t\", comment=\"#\", header=None)\n\n# renaming some columns\ngff.columns = [\"chr\", 1, \"region\", \"start\", \"end\", 4, \"strand\", 5, \"desc\"]\n\n\n# filtering for gene regions\ngff_genes = gff[gff[\"region\"] == \"gene\"]\ngff_genes.reset_index(drop=True, inplace=True)\n\nNext we extract genes related to resistance of Malaria drugs.\n\nimport re\nloci_locations = []\nlocis = [\"crt\", \"dhfr\", \"dhps\", \"mdr1\", \"Kelch13\", \"Plasmepsin\"]\nfor loci in locis:\n    pattern = 'Name=(.*' + loci.lower() +  '.*|.*' + loci.upper()  + '.*|' + loci + ').*;'\n    mask = [True if len(re.findall(pattern, desc)) > 0 else False for desc in gff_genes[\"desc\"]]\n    loci_locations.append(gff_genes[mask])\n\nloci_locations = pd.concat(loci_locations)\n# Plasmepsin not found (mostlikely different name)\nloci_locations.reset_index(drop=True, inplace=True)\n\n\nfor _, item in loci_locations.iterrows():\n    print(item[\"chr\"], item[\"start\"], item[\"end\"], item[\"end\"] - item[\"start\"],  item[\"desc\"])\n\nPf3D7_07_v3 402385 406341 3956 ID=PF3D7_0709000;Name=CRT;previous_systematic_id=MAL7P1.27\nPf3D7_04_v3 747897 750065 2168 ID=PF3D7_0417200;Name=DHFR-TS;previous_systematic_id=PFD0830w,MAL4P1.161;synonym=PfDHFR-TS%3Bcurrent%3Dfalse\nPf3D7_08_v3 547896 551057 3161 ID=PF3D7_0810800;Name=PPPK-DHPS;previous_systematic_id=PF08_0095\nPf3D7_05_v3 955955 963095 7140 ID=PF3D7_0523000;Name=MDR1;previous_systematic_id=PFE1150w,MAL5P1.230;synonym=Pgh1,ABCB1\nPf3D7_13_v3 1724600 1727877 3277 ID=PF3D7_1343700;Name=Kelch13;previous_systematic_id=PF13_0238;synonym=K13"
  },
  {
    "objectID": "session_1.html#loading-resistance-status-metadata",
    "href": "session_1.html#loading-resistance-status-metadata",
    "title": "1. Session - MalariaGEN",
    "section": "Loading resistance status metadata",
    "text": "Loading resistance status metadata\n\nresistance_url = \"https://www.malariagen.net/sites/default/files/Pf7_inferred_resistance_status_classification.txt\"\nresistance_status = pd.read_csv(io.StringIO(requests.get(resistance_url).content.decode('utf-8')), sep=\"\\t\")\n\nresistent_samples = []\nsensitive_samples = []\nundetermined_samples = []\n\nfor sample in kenyian_samples:\n    sulfadoxine = resistance_status[resistance_status[\"Sample\"] == sample][\"Sulfadoxine\"]\n    if len(sulfadoxine) == 1:\n        sulfadoxine = sulfadoxine.item()\n\n        if sulfadoxine == \"Resistant\":\n            resistent_samples.append(sample)\n        if sulfadoxine == \"Sensitive\":\n            sensitive_samples.append(sample)\n        else:\n            undetermined_samples.append(sample)"
  },
  {
    "objectID": "session_1.html#what-is-a-vcf-file-variant-call-format",
    "href": "session_1.html#what-is-a-vcf-file-variant-call-format",
    "title": "1. Session - MalariaGEN",
    "section": "What is a VCF file (Variant Call Format)?",
    "text": "What is a VCF file (Variant Call Format)?\nThe Variant Call Format (VCF) specifies the format of a text file used in bioinformatics for storing gene sequence variations. The format has been developed with the advent of large-scale genotyping and DNA sequencing projects, such as the 1000 Genomes Project.\n##fileformat=VCFv4.3\n##fileDate=20090805\n##source=myImputationProgramV3.1\n##reference=file:///seq/references/1000GenomesPilot-NCBI36.fasta\n##contig=<ID=20,length=62435964,assembly=B36,md5=f126cdf8a6e0c7f379d618ff66beb2da,species=\"Homo sapiens\",taxonomy=x>\n##phasing=partial\n##INFO=<ID=NS,Number=1,Type=Integer,Description=\"Number of Samples With Data\">\n##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total Depth\">\n##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency\">\n##INFO=<ID=AA,Number=1,Type=String,Description=\"Ancestral Allele\">\n##INFO=<ID=DB,Number=0,Type=Flag,Description=\"dbSNP membership, build 129\">\n##INFO=<ID=H2,Number=0,Type=Flag,Description=\"HapMap2 membership\">\n##FILTER=<ID=q10,Description=\"Quality below 10\">\n##FILTER=<ID=s50,Description=\"Less than 50% of samples have data\">\n##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\">\n##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read Depth\">\n##FORMAT=<ID=HQ,Number=2,Type=Integer,Description=\"Haplotype Quality\">\n#CHROM POS      ID         REF   ALT    QUAL  FILTER   INFO                             FORMAT       NA00001         NA00002          NA00003\n20     14370    rs6054257  G     A      29    PASS    NS=3;DP=14;AF=0.5;DB;H2           GT:GQ:DP:HQ  0|0:48:1:51,51  1|0:48:8:51,51   1/1:43:5:.,.\n20     17330    .          T     A      3     q10     NS=3;DP=11;AF=0.017               GT:GQ:DP:HQ  0|0:49:3:58,50  0|1:3:5:65,3     0/0:41:3\n20     1110696  rs6040355  A     G,T    67    PASS    NS=2;DP=10;AF=0.333,0.667;AA=T;DB GT:GQ:DP:HQ  1|2:21:6:23,27  2|1:2:0:18,2     2/2:35:4\n20     1230237  .          T     .      47    PASS    NS=3;DP=13;AA=T                   GT:GQ:DP:HQ  0|0:54:7:56,60  0|0:48:4:51,51   0/0:61:2\n20     1234567  microsat1  GTC   G,GTCT 50    PASS    NS=3;DP=9;AA=G                    GT:GQ:DP     0/1:35:4        0/2:17:2         1/1:40:3"
  },
  {
    "objectID": "session_1.html#extracting-gene-region-of-interest-from-vcf-file",
    "href": "session_1.html#extracting-gene-region-of-interest-from-vcf-file",
    "title": "1. Session - MalariaGEN",
    "section": "Extracting gene region of interest from VCF file",
    "text": "Extracting gene region of interest from VCF file\nTo create a vcf file which contains only PASS bi-allelic coding SNPs with VQSLOD > 6:\n\nbcftools view \\\n--include 'FILTER=\"PASS\" && N_ALT=1 && CDS==1 && TYPE=\"snp\" && VQSLOD>6.0' \\\n--regions Pf3D7_04_v3:600000-1000000 \\\n--output-type z \\\n--output-file DHFR-TS.vcf.gz \\\nPf3D7_04_v3.pf7.vcf.gz\nbcftools index --tbi DHFR-TS.vcf.gz\n\n\nbcftools view \\\n--include 'FILTER=\"PASS\" && N_ALT=1 && CDS==1 && TYPE=\"snp\" && VQSLOD>6.0' \\\n--regions Pf3D7_05_v3:800000-1100000 \\\n--output-type z \\\n--output-file MDR1_surrounding_region.vcf.gz \\\nPf3D7_05_v3.pf7.vcf.gz\nbcftools index --tbi MDR1_surrounding_region.vcf.gz"
  },
  {
    "objectID": "session_1.html#loading-vcf-file-and-calculating-nucleotide-diversity-tajimas-pi",
    "href": "session_1.html#loading-vcf-file-and-calculating-nucleotide-diversity-tajimas-pi",
    "title": "1. Session - MalariaGEN",
    "section": "Loading VCF file and calculating nucleotide diversity (Tajimas Pi)",
    "text": "Loading VCF file and calculating nucleotide diversity (Tajimas Pi)\n\n#pip install tsinfer tsdate scikit-allel numba matplotlib seaborn\n\n\nimport tsinfer, tsdate, allel\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# change the path to the file accordingly\n\n# in windows the file path looks something like 'C:/mydir'\n\nvcf_file = str(\"../../datasets/malaria-chromosomes/DHFR-TS_surrounding_region.vcf.gz\")\ncallset = allel.read_vcf(vcf_file, fields=['samples', 'calldata/GT', 'variants/ALT', 'variants/CHROM',\n                                            'variants/FILTER_PASS', 'variants/ID', 'variants/POS',\n                                            'variants/QUAL', 'variants/REF','calldata/GT','calldata/PS'])\n\ngt = allel.GenotypeArray(callset['calldata/GT'])\nphase_sets = callset['calldata/PS']\npos = callset[\"variants/POS\"]\n\ndef get_genotypes(samples, genotypes):\n    mask = [True if sample in samples else False for sample in callset[\"samples\"]]\n    genotypes = genotypes[:,mask]\n    gt_np = np.array(genotypes.to_haplotypes())\n    return gt_np\n\ngt_kenyian = get_genotypes(kenyian_samples, gt)\ngt_resistant_kenyian = get_genotypes(resistent_samples, gt)\ngt_sensitive_kenyian = get_genotypes(sensitive_samples, gt)\nac = gt_sensitive_kenyian\npi, windows, n_bases_sen, counts_sen = allel.windowed_diversity(pos=pos, ac=ac, size=10_000, start=pos[0])\nwindow_start = pd.DataFrame(windows)[0]\nsns.lineplot(x=window_start, y=pi, label=\"Nucleotide Diversity (sensitive)\")\n\n\nac = gt_resistant_kenyian\npi, windows, n_bases_res, counts_res = allel.windowed_diversity(pos=pos, ac=ac, size=10_000, start=pos[0])\nwindow_start = pd.DataFrame(windows)[0]\nsns.lineplot(x=window_start, y=pi, label=\"Nucleotide Diversity (resistant)\")\n\nplt.axvline(747897, ls='--')\nplt.axvline(750065, ls='--')\nplt.grid(True)\n\nplt.suptitle(\"DHFR (Sulfadoxine target)\")\n#plt.savefig(\"./images/dhfr_scikit.png\")\n\n\n\nDHFR gene"
  },
  {
    "objectID": "session_1.html#an-alternative-possibilty-is-to-go-through-constructing-the-genealogies",
    "href": "session_1.html#an-alternative-possibilty-is-to-go-through-constructing-the-genealogies",
    "title": "1. Session - MalariaGEN",
    "section": "An alternative possibilty is to go through constructing the genealogies",
    "text": "An alternative possibilty is to go through constructing the genealogies\n\ndef get_tree_sequence_from_genotypes(samples, genotypes):\n\n    mask = [True if sample in samples else False for sample in callset[\"samples\"]]\n    genotypes = genotypes[:,mask]\n    gt_np = np.array(genotypes.to_haplotypes())\n\n    new_pos = pos - pos[0] \n    num_sites = gt_np.shape[0]\n    with tsinfer.SampleData(sequence_length=new_pos[-1]+1) as sample_data:\n        for i, site in enumerate(gt_np):\n            sample_data.add_site(new_pos[i], site, ancestral_allele=0)\n\n    inferred_ts = tsinfer.infer(sample_data)\n    #inferred_ts_reduced = reduce_tree_sequence(inferred_ts, 500)\n\n    inferred_ts = inferred_ts.simplify(keep_unary=False)\n    inferred_dated_ts= tsdate.date(inferred_ts, Ne=2000, mutation_rate=2 * 10e-4)\n    return inferred_dated_ts\n\nts_all = get_tree_sequence_from_genotypes(kenyian_samples, gt)\nts_resistant = get_tree_sequence_from_genotypes(resistent_samples, gt)\nts_sensitive = get_tree_sequence_from_genotypes(sensitive_samples, gt)\n\ndef get_stats(ts, wins):\n\n    tajima = ts.Tajimas_D(windows=wins, mode=\"site\")\n    diversity = ts.diversity(windows=wins, mode=\"site\")\n    return diversity, tajima\n\nL = ts_all.sequence_length\nwins = np.linspace(0, L, 31)\nmids = (wins[1:] + wins[:-1]) / 2\n\ndiversity, tajima = get_stats(ts_all, wins)\ndiversity_res, tajima_res = get_stats(ts_resistant, wins)\ndiversity_sens, tajima_sens = get_stats(ts_sensitive, wins)\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\nax = axs[0][0]\nsns.lineplot(x=mids, y=diversity_sens, ax=ax, label=\"Nucleotide diversity\")\nax.axvline(747897-pos[0], ls='--')\nax.axvline(750065-pos[0], ls='--')\nax.grid(True)\nax = axs[0][1]\nsns.lineplot(x=mids, y=tajima_sens, ax=ax, label=\"Tajimas D\")\nax.set_ylim(-2, 2)\nax.axhline(0)\nax.axvline(747897-pos[0], ls='--')\nax.axvline(750065-pos[0], ls='--')\nax.grid(True)\nax = axs[1][0]\nsns.lineplot(x=mids, y=diversity_res, ax=ax, label=\"Nucleotide diversity\")\nax.axvline(747897-pos[0], ls='--')\nax.axvline(750065-pos[0], ls='--')\nax.grid(True)\nax = axs[1][1]\nsns.lineplot(x=mids, y=tajima_res, ax=ax, label=\"Tajimas D\")\nax.set_ylim(-2, 2)\nax.axhline(0)\nax.axvline(747897-pos[0], ls='--')\nax.axvline(750065-pos[0], ls='--')\nax.grid(True)\nfig.suptitle(\"DHFR (Sulfadoxine target - sensitive [top] resistant [bottom])\")\n\n\n#plt.savefig(\"./images/dhfr.png\")\n\n\n\nDHFR gene"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Summer School Epidemiology 2023",
    "section": "",
    "text": "The aim of this website is to provide a resource of methods used in the SSE2023 for the workshop part of Prof. Aurelien Tellier and Kevin Korfmann. We will provide an overview of three different sessions. A brief outline of the subjects related to research of the Professorship of population genetics will be explored through the following topics:\n\nSession - MalariaGen\nSession - Introduction to Deep Learning and Dataset Generation\nSession - Training and Inference of Coalescent Models"
  },
  {
    "objectID": "session_2.html",
    "href": "session_2.html",
    "title": "2. Session - Introduction to Deep Learning and Dataset Generation",
    "section": "",
    "text": "The aim of this session is provide an intuition of what is it like to develop and apply neural networks using PyTorch, a popular deep learing framework."
  },
  {
    "objectID": "session_2.html#dlmachine-learning-paradigm",
    "href": "session_2.html#dlmachine-learning-paradigm",
    "title": "2. Session - Introduction to Deep Learning and Dataset Generation",
    "section": "2.0 DL/Machine Learning Paradigm",
    "text": "2.0 DL/Machine Learning Paradigm\nMachine learning (ML) and deep learning (DL) are two subfields of artificial intelligence (AI) that aim to enable computers to learn from data and improve their performance on a specific task without being explicitly programmed. The general paradigm of ML and DL involves the following steps:\n\nData collection: The first step is to gather the data that will be used to train the machine learning algorithm. This can involve collecting data from various sources, such as sensors, databases, or the internet.\nData preprocessing: The collected data needs to be cleaned, transformed, and prepared for the machine learning algorithm. This step includes tasks such as removing irrelevant or redundant data, handling missing values, and scaling the features.\nModel selection: The next step is to select a machine learning model that is appropriate for the task at hand. There are many different types of machine learning models, such as linear regression, decision trees, and neural networks, and the choice depends on the specific problem.\nModel training: In this step, the selected machine learning model is trained on the preprocessed data. The goal is to find the optimal parameters that minimize the error between the predicted outputs and the actual outputs.\nModel evaluation: Once the machine learning model is trained, it needs to be evaluated to measure its performance on new, unseen data. This step helps to ensure that the model is not overfitting to the training data and can generalize well to new data.\nModel application: Finally, the machine learning model can be deployed in a real-world environment where it can be used to make predictions or decisions.\n\nDeep learning is a specific type of machine learning that uses neural networks with many layers to learn complex representations of the input data. The general paradigm of deep learning is similar to that of machine learning, but it typically involves larger datasets, more complex models, and longer training times. Deep learning models often require specialized hardware, such as graphics processing units (GPUs), to train efficiently."
  },
  {
    "objectID": "session_2.html#deep-learning-models",
    "href": "session_2.html#deep-learning-models",
    "title": "2. Session - Introduction to Deep Learning and Dataset Generation",
    "section": "2.1 Deep learning models",
    "text": "2.1 Deep learning models\nThere are several types of deep learning models that are used for different tasks and on different types of data. The basic building block of most deep learning models is the neural network, which consists of layers of interconnected nodes (neurons) that perform mathematical operations on the input data to produce an output.\nHere are some of the most common types of deep learning models:\n\nConvolutional Neural Networks (CNNs): CNNs are a type of neural network that is used for image classification, object detection, and other computer vision tasks. They are designed to process data that has a grid-like structure, such as images, and use convolutional layers to extract features from the input. The input to a CNN is a tensor of shape (width, height, channels), where channels correspond to the color channels of the image (e.g. red, green, blue).\nRecurrent Neural Networks (RNNs): RNNs are a type of neural network that is used for sequential data, such as time series data or natural language processing. They use recurrent layers to maintain a memory of previous inputs, which allows them to model temporal dependencies in the data. The input to an RNN is a sequence of vectors, where each vector corresponds to a timestep in the sequence.\nLong Short-Term Memory (LSTM) Networks: LSTMs are a type of RNN that is specifically designed to handle long-term dependencies in the input data. They use a special type of recurrent layer that can selectively remember or forget previous inputs. They have often been used for natural language processing tasks such as language modeling or machine translation.\nGenerative Adversarial Networks (GANs): GANs are a type of neural network that is used for generative tasks, such as image synthesis and text generation. They consist of two neural networks that are trained in a game-like setting, with one network generating fake data and the other network trying to distinguish between real and fake data.\nAutoencoders: Autoencoders are a type of neural network that is used for unsupervised learning and dimensionality reduction. They are designed to encode the input data into a lower-dimensional representation and then decode it back into the original form, with the goal of minimizing the reconstruction error.\nTransformers: Transformers are a type of neural network that is used for natural language processing tasks, such as language translation and text summarization. They use self-attention mechanisms to process input sequences and can model long-range dependencies in the data."
  },
  {
    "objectID": "session_2.html#training-loop",
    "href": "session_2.html#training-loop",
    "title": "2. Session - Introduction to Deep Learning and Dataset Generation",
    "section": "2.2 Training loop",
    "text": "2.2 Training loop\nIn deep learning, the model is typically a neural network with many layers, and the training loop involves adjusting the weights and biases of these layers to minimize the error between the predicted output and the true output. The training loop consists of the following steps:\n\nData preprocessing: The first step in the training loop is to preprocess the input data to prepare it for use in the neural network. This may involve tasks such as normalization, scaling, or data augmentation.\nForward pass: The next step is to perform a forward pass through the neural network using the input data. The output of each layer is passed as input to the next layer, and the process continues until the final layer produces the predicted output.\nCompute loss: The predicted output is compared to the true output to compute the loss or error between them. The loss function is a measure of how well the model is performing on the training data.\nBackward pass: The backward pass, also known as backpropagation, involves computing the gradients of the loss with respect to the weights and biases of the neural network. This is done using the chain rule of calculus to propagate the error backwards through the network.\nUpdate weights and biases: The gradients computed in the backward pass are used to update the weights and biases of the neural network. This is done using an optimization algorithm such as stochastic gradient descent (SGD), which adjusts the weights and biases in the direction that minimizes the loss function.\nRepeat: The above steps are repeated for a fixed number of iterations or until the model achieves a satisfactory level of performance on the training data. In practice, the training loop is often run for many epochs, with the entire training dataset passed through the network multiple times.\nEvaluation: After training is complete, the model is evaluated on a separate test dataset to measure its performance on new, unseen data.\n\nThe above steps constitute the basic training loop for deep learning. In practice, there are many variations and extensions to this loop, such as regularization, early stopping, and learning rate scheduling, all of which can improve the performance of the model and make the training process more efficient."
  },
  {
    "objectID": "session_2.html#example-for-inference-of-balancing-selection",
    "href": "session_2.html#example-for-inference-of-balancing-selection",
    "title": "2. Session - Introduction to Deep Learning and Dataset Generation",
    "section": "2.3 Example for inference of balancing selection",
    "text": "2.3 Example for inference of balancing selection\nPrerequisits - Balancing selection:\nBalancing selection is a type of natural selection that maintains genetic diversity in a population by favoring the maintenance of multiple alleles at a particular locus. This can occur through a variety of mechanisms, such as heterozygote advantage, frequency-dependent selection, or spatially variable selection. Balancing selection is in contrast to directional selection, which favors the fixation of a single allele over time.\nOne type of balancing selection is overdominance, also known as heterozygote advantage. Overdominance occurs when the heterozygote genotype has a higher fitness than either of the homozygote genotypes. This can occur, for example, when different alleles at a particular locus confer resistance to different diseases or environmental stressors, or when different alleles have complementary functions. In these cases, individuals that are heterozygous for the locus have a selective advantage over individuals that are homozygous for either allele, leading to the maintenance of both alleles in the population.\nOverall, balancing selection is an important mechanism for maintaining genetic diversity in populations, and overdominance is one specific type of balancing selection that can lead to the maintenance of multiple alleles at a particular locus.\nTo illustrate the steps of the training loop described above we show a simple example of inferring balancing selection. Is taken from the above, but a description of inference is task is provided below:\n“To illustrate the ability of deep learning to detect signals of recent balancing selection, we simulated a scenario inspired by available data in human population genetics. We simulated 2,000 50 kbp loci under either neutrality or overdominance (i.e. heterozygote advantage, a form of balancing selection) at the center of the locus, conditioned to a demographic model of European populations (Jouganous et al. 2017). We performed forward-in-time simulations using SLiM (Haller and Messer 2019), similarly to a previous study (Isildak et al. 2021). We imposed selection on a de novo mutation starting 10k years ago, with selection coefficients of 0.25% and 0.5%. We sampled 40 present-day haplotypes, and 10 ancient haplotypes at four different time points (8k, 4k, 2k, 1k years ago, mirroring a plausible human aDNA data collection).”\n\n2.3.1 Coding start\nUsually we would start by setting up our simulator to train our training data, but in this case we already have simulations which we can use as training/testing dataset available.\n\n# pip install scikit-learn\n# pip install chardet\n\n\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nfrom torchvision import models\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\nimport os\nimport copy\nimport time\n\nfrom workshop_kenya.msms2haplo import *\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndata_path = Path(\"/home/kevinkorfmann/Projects/temporal-balancing-selection/temp-balance-data\")\n\n\ndef get_paths(directories):\n    all_files = []\n    for d in directories:\n        path = Path(d)\n        files = os.listdir(path)\n        files = [path/file for file in files]\n        all_files.append(files)\n    return all_files\n\n\ndef ancient_files_to_X(files):\n    Xs = []\n    for i in range(len(files[0])):\n        file_time0, file_time1, file_time2, file_time3 = files[0][i], files[1][i], files[2][i], files[3][i]\n        files_timepoints = [file_time0, file_time1, file_time2, file_time3]\n        matrices_timepoints = []\n        for file in files_timepoints:\n            chroms, positions = read_msms(filename=file, NCHROMS=10)\n            chroms = sort_min_diff(chroms)\n            matrices_timepoints.append(torch.Tensor(myresize(chroms)))\n        Xs.append(torch.vstack(matrices_timepoints))\n    X = torch.stack(Xs)\n    X = X.unsqueeze(1)\n    return X\n\n\ndef recent_files_to_X(files):\n    Xs = []\n    for i in range(len(files[4])):\n        file_time = files[4][i]\n        files_timepoints = [file_time]\n        matrices_timepoints = []\n        for file in files_timepoints:\n            chroms, positions = read_msms(filename=file, NCHROMS=40)\n            chroms = sort_min_diff(chroms)\n            matrices_timepoints.append(torch.Tensor(myresize(chroms)))\n        Xs.append(torch.vstack(matrices_timepoints))\n    X = torch.stack(Xs)\n    X = X.unsqueeze(1)\n    return X\n\ndef myresize(chroms):\n    chroms = torch.Tensor(chroms)\n    if chroms.shape[1] >= 40:\n        chroms = chroms[:,:40]\n    else:\n        snp_dim = chroms.shape[1]\n        addzeros = 40 - snp_dim -1\n        chroms = F.pad(chroms, (1, addzeros), \"constant\", 0)\n    return chroms\n\n\ndirectories =  [data_path/\"neutral/1\", data_path/\"neutral/2\", data_path/\"neutral/3\", data_path/\"neutral/4\", data_path/\"neutral/5\"]\nfiles_neutral = get_paths(directories)\n\ndirectories =  [data_path/\"dominance0025/1\", data_path/\"dominance0025/2\", data_path/\"dominance0025/3\", data_path/\"dominance0025/4\", data_path/\"dominance0025/5\"]\nfiles_dominance0025 = get_paths(directories)\n\ndirectories =  [data_path/\"dominance05/1\", data_path/\"dominance05/2\", data_path/\"dominance05/3\", data_path/\"dominance05/4\", data_path/\"dominance05/5\"]\nfiles_dominance05 = get_paths(directories)\nnum_samples = 1000\n\nXa_neutral = ancient_files_to_X(files_neutral)\nya_neutral = torch.Tensor([0]*num_samples).long()\n\nXa_dominance0025 = ancient_files_to_X(files_dominance0025)\nya_dominance0025 = torch.Tensor([1]*num_samples).long()\n\nXa_dominance05 = ancient_files_to_X(files_dominance05)\nya_dominance05 = torch.Tensor([2]*num_samples).long()\n\nXa = torch.cat([Xa_neutral, Xa_dominance05, Xa_dominance0025], axis=0)\nya = torch.cat([ya_neutral, ya_dominance05, ya_dominance0025], axis=0)\n\n#print(f\"Shape of X (ancient) {Xa.shape}\")\n#print(f\"Shape of y (ancient) {ya.shape}\")\n\nShape of X (ancient) torch.Size([3000, 1, 40, 40])\nShape of y (ancient) torch.Size([3000])\n\n\n\nnum_samples = 1000\n\nXr_neutral = recent_files_to_X(files_neutral)\nyr_neutral = torch.Tensor([0]*num_samples).long()\n\nXr_dominance05 = recent_files_to_X(files_dominance05)\nyr_dominance05 = torch.Tensor([2]*num_samples).long()\n\nXr_dominance0025 = recent_files_to_X(files_dominance0025)\nyr_dominance0025 = torch.Tensor([1]*num_samples).long()\n\nXr = torch.cat([Xr_neutral, Xr_dominance05, Xr_dominance0025], axis=0)\nyr = torch.cat([yr_neutral, yr_dominance05, yr_dominance0025], axis=0)\n\n# print(f\"Shape of X (ancient) {Xr.shape}\")\n# print(f\"Shape of y (ancient) {yr.shape}\")\n\nShape of X (ancient) torch.Size([3000, 1, 40, 40])\nShape of y (ancient) torch.Size([3000])\n\n\n\nrandom_idx = np.random.choice(range(0,3000), 3000)\n\n\nclass BalancingSelectionDataset(Dataset):\n    \"\"\"BalancingSelectionDataset dataset.\"\"\"\n\n    def __init__(self, Xa, Xr, ya, yr):\n        self.Xa = Xa\n        self.ya = ya\n        self.Xr = Xr\n        self.yr = yr\n\n    def __len__(self):\n        return self.Xa.shape[0]\n\n    def __getitem__(self, idx):\n        return self.Xa[idx], self.Xr[idx], self.ya[idx], self.yr[idx]\n\n\ndef get_dataloader(Xa, Xr, ya, yr):\n    \n    split = 1000\n    bs_val_dataset = BalancingSelectionDataset(Xa[random_idx[0:split]], Xr[random_idx[0:split]], ya[random_idx[0:split]], yr[random_idx[0:split]])\n    \n    bs_train_dataset = BalancingSelectionDataset(Xa[random_idx[split:]], Xr[random_idx[split:]], ya[random_idx[split:]], yr[random_idx[split:]])\n    \n    dataset_sizes = {}\n    dataset_sizes[\"train\"] = len(bs_train_dataset)\n    dataset_sizes[\"val\"] = len(bs_val_dataset)\n    train_dl = torch.utils.data.DataLoader(bs_train_dataset, batch_size=16, shuffle=True, num_workers=4)\n    val_dl = torch.utils.data.DataLoader(bs_val_dataset, batch_size=16, shuffle=True, num_workers=4)\n    dataloaders = {\"train\":train_dl, \"val\":val_dl}\n    return dataloaders, dataset_sizes\n\n\ndef ensemble_train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for Xa, Xr, ya, yr in dataloaders[phase]:\n                \n                Xa = Xa.to(device)\n                Xr = Xr.to(device)\n                ya = ya.to(device)\n                yr = yr.to(device)\n                \n                #assert ya == yr\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(Xa, Xr)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, ya)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * Xa.size(0)\n                running_corrects += torch.sum(preds == ya.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\n\nclass TwoBranchEnsembleModel(nn.Module):\n    def __init__(self, ancient_model, recent_model, nb_classes=2):\n        super(TwoBranchEnsembleModel, self).__init__()\n        \n        self.ancient_model = ancient_model\n        self.recent_model = recent_model\n        \n        input_size = num_output_layers_single_model+num_output_layers_single_model\n        \n        self.l0 = nn.Linear(input_size, input_size//2)\n        self.l1 = nn.Linear(input_size//2, input_size//4)\n        self.l2 = nn.Linear(input_size//4, nb_classes)\n\n        \n        \n    def forward(self, ancient_data, recent_data):\n        x0 = self.ancient_model(ancient_data)  \n        x1 = self.recent_model(recent_data) \n        \n        x = torch.cat((x0, x1), dim=1)\n        \n        x = self.l0(F.relu(x))\n        x = self.l1(F.relu(x))\n        x = self.l2(F.relu(x))\n        \n        return x\n    \ndef create_convnet(num_output_layers=2):\n    model = models.resnet18(pretrained=False)    \n    model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n    model.fc = nn.Linear(model.fc.in_features, num_output_layers)\n    return model\n\n\nconfusion_matrices_both_recent_ancient = []\n\nfor _ in tqdm(range(3)):\n\n    # get dataloaders\n    dataloaders, dataset_sizes = get_dataloader(Xa, Xr, ya, yr)\n    \n    # prepare ensemble model\n    num_output_layers_single_model = 64\n    ancient_model = create_convnet(num_output_layers=num_output_layers_single_model)\n    recent_model = create_convnet(num_output_layers=num_output_layers_single_model)\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = TwoBranchEnsembleModel(ancient_model, recent_model, nb_classes=3).to(device)\n\n    # prepare training\n    criterion = nn.CrossEntropyLoss()\n    optimizer_ft = optim.Adam(model.parameters(), lr=0.0005)\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\n    \n    # train for 3 epochs\n    model = ensemble_train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=4)\n\n\n    # validate\n    y_hat = []\n    y_true = []\n    with torch.no_grad():\n        for Xba, Xbr, yba, ybr in dataloaders[\"val\"]:\n            Xba = Xba.to(device)\n            Xbr = Xbr.to(device)\n            yba = yba.to(device)\n            ybr = ybr.to(device)\n            outputs = model(Xba, Xbr)\n            _, preds = torch.max(outputs, 1)\n            y_hat += preds.cpu().numpy().tolist()\n            y_true += yba.cpu().numpy().tolist()\n\n\n    # save confusion\n    cm = confusion_matrix(y_true, y_hat)\n    cm = cm / cm.sum(1)\n\n    confusion_matrices_both_recent_ancient.append(cm)\n\ndef plot_confusion_matrix(confusion_matrices, ax):\n\n    bootstrap_cm = np.array(confusion_matrices).mean(0)\n    bootstrap_stds = np.array(confusion_matrices).std(0)\n\n    # standard deviation labels\n    accuracies = [str(np.round(v, 2)) for v in bootstrap_cm.flatten().tolist()]\n    stds = [str(np.round(v, 2)) for v in bootstrap_stds.flatten().tolist()]\n    labels = [a  + \"±\\n\" + s for a, s in zip(accuracies, stds)]\n    labels = np.array(labels).reshape(3,3)\n    \n    sns.heatmap(bootstrap_cm, annot = labels, fmt = '', cmap=\"Blues\", ax=ax, xticklabels=[\"N\", \"D0.25\", \"D0.5\"], yticklabels=[\"N\", \"D0.25\", \"D0.5\"], linecolor='black', linewidths=.5)\n\n    ax.axhline(y=0, color='k',linewidth=5)\n    ax.axhline(y=3, color='k',linewidth=5)\n    ax.axvline(x=0, color='k',linewidth=5)\n    ax.axvline(x=3, color='k',linewidth=5)\n\nimport seaborn as sns \n\nsns.set(style=\"white\", font_scale=1.75)\n\nfig, ax = plt.subplots(1 , sharex=True, sharey=True, figsize=(7, 7))\nplot_confusion_matrix(confusion_matrices_both_recent_ancient, ax)\nax.set_title(\"ancient+recent\")\n\n#plt.savefig(\"./images/confusion.png\", dpi=250)\n\n\n\n\nConfusion matrix"
  },
  {
    "objectID": "introduction_to_deep_learning.html",
    "href": "introduction_to_deep_learning.html",
    "title": "Introduction to Deep Learning (DL)",
    "section": "",
    "text": "This notebook is intented to give a brief overview over the field of DL."
  },
  {
    "objectID": "introduction_to_deep_learning.html#what-is-dl",
    "href": "introduction_to_deep_learning.html#what-is-dl",
    "title": "Introduction to Deep Learning (DL)",
    "section": "What is DL?",
    "text": "What is DL?\n\n\n\n\nA deep neural network is a neural network with many layers -> allowing it to learn hierarchical representations of data.\nThe output of each layer is a nonlinear transformation of the weighted sum of the inputs.\nMathematically, we can represent the output of a layer l with \\(n_l\\) neurons as:\n\\(h_l = g(W_l h_{l-1} + b_l)\\)\nwhere \\(h_{l-1}\\) is the output of the previous layer, \\(W_l\\) is the weight matrix connecting the neurons of layer \\(l-1\\) to layer \\(l\\), \\(b_l\\) is the bias vector for layer \\(l\\), and \\(g\\) is a nonlinear activation function.\nThe training process involves feeding the network a large amount of labeled data and adjusting the network’s parameters to minimize a loss function that measures the difference between the predicted outputs and the true outputs. This is typically done using gradient-based optimization algorithms, such as stochastic gradient descent. Mathematically, we can express the loss function L as:\n\\(L = 1/N \\sum_{i=1}^N L_i(y_i, f(x_i; \\theta))\\)\nwhere N is the number of training samples, \\(x_i\\) and \\(y_i\\) are the input and output of the i-th sample, \\(f(x_i; \\theta)\\) is the output of the neural network with parameters \\(\\theta\\), and \\(L_i\\) is a per-sample loss function, such as the mean squared error (MSE) or the cross-entropy loss.\n\nBackpropagation:\n* Once the loss has been computed, the next step is to update the parameters of the model (i.e., the weights and biases) to reduce the loss on the training data. Backpropagation is an algorithm used to compute the gradients of the loss with respect to the model parameters.\n\nBy repeating the process of computing the loss and backpropagating the gradients, the neural network gradually learns to make more accurate predictions on the training data. The goal of training is to find the set of parameters that minimizes the loss on the training data while still generalizing well to new, unseen data."
  },
  {
    "objectID": "introduction_to_deep_learning.html#brief-historical-overview",
    "href": "introduction_to_deep_learning.html#brief-historical-overview",
    "title": "Introduction to Deep Learning (DL)",
    "section": "Brief historical overview",
    "text": "Brief historical overview\n\n1940s 50s- From formulation to implementation\n\nDL history dates back 1943 to Warren McCulloch and Walter Pitts\nMathematical representation of neurons in the brain might work\nGiven the input x = [ x₁, x₂, x₃, …, xₙ ]ᵀ, the inhibitory input i and the threshold Θ, the output y is computed as follows:\n\n\n\n\n\nMarvin Minsky and Dean Edmonds developed the first neural network computer, called the SNARC (The Stochastic Neural Analog Reinforcement Calculator); designed of tasks like desicion making with human feedback (i.e. navigating through a maze)\n\n\n\n\n\nFrank Rosenblatt developed the perceptron and simple optimization algorithm\n\n\n\n\n\n\n\n\n\nBrief description of learning algorithm\n\nAssume that the mᵗʰ example xₘ belongs to class yₘ=0 and that the perceptron correctly predicts ŷₘ =0. In this case, the weight correction is given by Δw = ( 0-0 ) xₘ, i.e. we do not change the weights. The same applies to bias.\nSimilarly, if the mᵗʰ example xₘ belongs to class yₘ=1 and the perceptron correctly predicts ŷₘ =1, then the weight correction is Δw = 0. The same applies again for the bias.\nAssume now that the mᵗʰ example xₘ belongs to class yₘ=0 and that the perceptron wrongly predicts ŷₘ =1. In this case, the weight correction is given by Δw = ( 0–1 ) xₘ = –xₘ, while the bias is updated as b = b–1.\nFinally, if the mᵗʰ example xₘ belongs to class yₘ=1 and the perceptron wrongly predicts ŷₘ =0, the weight correction is Δw = xₘ. The bias is also updated according to b = b+1\n\n(See also Learning algorithm)\n“Stories about the creation of machines having human qualities have long been a fascinating province in the realm of science fiction,” Rosenblatt wrote in 1958. “Yet we are about to witness the birth of such a machine – a machine capable of perceiving, recognizing and identifying its surroundings without any human training or control.”\n\n\n\n1960s - AI winter\n\nDue to limitations of early networks, different research directions in AI become more popular, e.g. Knowledge-Bases and Rule-based systems\n\n\n\n1970s - 1990s - Incremental Progress\n\nComputing power still limited but slow incremental progression\nDevelopement of Backpropagation algorithm (Optimization algorithm)\nConceptualization of architecture like CNN, RNN, LSTM\n\n\n\n2000s - From the Vanishing Gradients to ImageNet\n\nThe “Vanishing Gradient Problem” made it difficult to train models with many layers\nFirst techniques were developed to address the issue, i.e. using activation functions\n2009: ImageNet competition"
  },
  {
    "objectID": "introduction_to_deep_learning.html#machine-learning-ml-dl-paradigm",
    "href": "introduction_to_deep_learning.html#machine-learning-ml-dl-paradigm",
    "title": "Introduction to Deep Learning (DL)",
    "section": "Machine Learning (ML)/ DL Paradigm",
    "text": "Machine Learning (ML)/ DL Paradigm\n\n\n\nThere are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.\n\nIn supervised learning, the algorithm is trained on a set of input-output pairs, and the goal is to learn a function that maps inputs to outputs.\nIn unsupervised learning, the algorithm is trained on a set of input data without any labels, and the goal is to learn the underlying structure or patterns in the data.\nIn reinforcement learning, the algorithm learns to make decisions by interacting with an environment and receiving feedback in the form of rewards or punishments.\n\n\nDomains\n\nComputer Vision: Neural networks are widely used for tasks such as object detection, image segmentation, and image classification.\n\nSelf-driving cars\nFacial recognition\nMedical image analysis\n\nNatural Language Processing (NLP): Neural networks can be used for tasks such as sentiment analysis, language translation, and speech recognition.\n\nChatbots\nVirtual assistants\nLanguage translation services.\n\nRobotics: Neural networks are used in robotics for tasks such as object detection and grasping, path planning, and motion control.\n\nIndustrial automation\nAutonomous drones\nHumanoid robots\n\nGaming: Neural networks can be used to build intelligent game agents that can learn to play games such as chess, Go, and video games.\nFinance: Neural networks can be used for tasks such as fraud detection, risk assessment, and portfolio optimization.\n\nFraud detection systems\nCredit scoring models\nTrading algorithms.\n\nHealthcare: Neural networks are used for tasks such as disease diagnosis, drug discovery, and personalized medicine.\n\nMedical imaging analysis\nClinical decision support systems\nDrug discovery pipelines\n\nMarketing: Neural networks can be used for tasks such as customer segmentation, recommendation systems, and predictive modeling.\n\nTargeted advertising\nCustomer retention\nProduct recommendations\n\n\n\n\nThe Concept of Embeddings\nEmbedding” is a general term used in machine learning and refers to the process of mapping a high-dimensional, discrete or categorical input into a continuous, low-dimensional vector space (embedding space) where similar inputs are close to each other. In neural networks, embeddings are often learned in an unsupervised manner, meaning that the embedding space is learned from the data itself, without the need for explicit supervision.\nEmbeddings are widely used in natural language processing (NLP) and graph neural networks (GNNs), among other areas. Here are some specific examples:\nNLP: In NLP, embeddings are often used to represent words or phrases as vectors in a continuous space, which can capture semantic and syntactic similarities between words. Word embeddings are typically learned by training a neural network to predict a word from its context (i.e., neighboring words), using a technique called Word2Vec. Once learned, these embeddings can be used as input features for downstream NLP tasks, such as sentiment analysis or named entity recognition.\n\nGNNs: In GNNs, embeddings are used to represent nodes or edges in a graph as vectors in a continuous space, which can capture the structural similarities and relationships between them. Graph embeddings are typically learned by training a neural network to predict the presence or absence of edges between nodes in a graph, using techniques such as graph convolutional networks (GCNs) or graph attention networks (GATs). Once learned, these embeddings can be used as input features for downstream GNN tasks, such as node classification or link prediction.\nOverall, embeddings are a powerful tool for reducing the dimensionality of high-dimensional inputs and capturing their inherent structure and relationships. They have been used successfully in a wide range of machine learning applications, particularly in NLP and GNNs."
  },
  {
    "objectID": "introduction_to_deep_learning.html#modelsarchitectures-and-applications",
    "href": "introduction_to_deep_learning.html#modelsarchitectures-and-applications",
    "title": "Introduction to Deep Learning (DL)",
    "section": "Models/Architectures and Applications",
    "text": "Models/Architectures and Applications\n\nConvolutional Neural Networks (CNNs): CNNs are a type of neural network that is used for image classification, object detection, and other computer vision tasks. They are designed to process data that has a grid-like structure, such as images, and use convolutional layers to extract features from the input. The input to a CNN is a tensor of shape (width, height, channels), where channels correspond to the color channels of the image (e.g. red, green, blue).\n\n\n\n\n\nRecurrent Neural Networks (RNNs): RNNs are a type of neural network that is used for sequential data, such as time series data or natural language processing. They use recurrent layers to maintain a memory of previous inputs, which allows them to model temporal dependencies in the data. The input to an RNN is a sequence of vectors, where each vector corresponds to a timestep in the sequence.\n\n\n\n\n\nLong Short-Term Memory (LSTM) Networks: LSTMs are a type of RNN that is specifically designed to handle long-term dependencies in the input data. They use a special type of recurrent layer that can selectively remember or forget previous inputs. They have often been used for natural language processing tasks such as language modeling or machine translation.\n\n\n\n\n\nGenerative Adversarial Networks (GANs): GANs are a type of neural network that is used for generative tasks, such as image synthesis and text generation. They consist of two neural networks that are trained in a game-like setting, with one network generating fake data and the other network trying to distinguish between real and fake data.\n\n\n\n\n\nAutoencoders: Autoencoders are a type of neural network that is used for unsupervised learning and dimensionality reduction. They are designed to encode the input data into a lower-dimensional representation and then decode it back into the original form, with the goal of minimizing the reconstruction error.\n\n\n\n\n\nSeq2Seq models: Translation tasks/sentiment analysis\n\n\n\nTransformers: Transformers are a type of neural network that is used for natural language processing tasks, such as language translation and text summarization. They use self-attention mechanisms to process input sequences and can model long-range dependencies in the data.\n\n\n\n\n\nGraph neural networks: Generalization the convolution operator from CNNs, to aggregate information over nodes and edges.\n\n\n\n\n\nDiffusion Networks: The modern diffusion networks used in deep dream are a type of generative model that leverages the power of the diffusion process to generate images by gradually diffusing noise into the network and mapping it to a target distribution."
  },
  {
    "objectID": "introduction_to_deep_learning.html#the-importance-of-frameworks",
    "href": "introduction_to_deep_learning.html#the-importance-of-frameworks",
    "title": "Introduction to Deep Learning (DL)",
    "section": "The Importance of Frameworks",
    "text": "The Importance of Frameworks\nDeep learning frameworks provide a powerful set of tools for building, training, and deploying deep neural networks, which have shown exceptional performance on a wide range of tasks. * Quick prototyping, easy experimental setup, availability of proven architecture, hyperparameter, data pipelines * High level abstraction of underlying computation, enable possibility of complex models, no need to worry about memory management * Open-source and activily maintained * Hardware-support (GPUs, TPU, …) * Standardized interface for pretained, state-of-the-art models (see transfer learning)\nMostpopular frameworks include (Google-developed Tensorflow or) Facebooks Pytorch"
  },
  {
    "objectID": "introduction_to_deep_learning.html#active-research-areas-beyond-the-model",
    "href": "introduction_to_deep_learning.html#active-research-areas-beyond-the-model",
    "title": "Introduction to Deep Learning (DL)",
    "section": "Active Research Areas beyond the Model",
    "text": "Active Research Areas beyond the Model\n\nOptimization techniques: Developing more efficient and effective optimization algorithms to train deep neural networks.\nInterpretability and explainability: Understanding and interpreting the decisions made by deep learning models, and making them more transparent and interpretable.\nTransfer learning: Investigating ways to transfer knowledge from one task or domain to another, allowing deep learning models to be trained with less data and time.\nAdversarial attacks and defenses: Studying how deep learning models can be attacked or fooled, and developing defenses against such attacks.\nUncertainty estimation: Developing techniques to estimate the uncertainty of deep learning models, which is important for applications such as autonomous driving and medical diagnosis.\nReinforcement learning: Developing deep learning models that can learn from trial and error, and apply this knowledge to make decisions in complex environments.\nFederated learning: Investigating techniques for training deep learning models on decentralized data, allowing for better privacy and security.\nHardware and software acceleration: Developing specialized hardware and software for deep learning, to improve performance and efficiency.\nMulti-task learning: Studying ways to train deep learning models to perform multiple tasks simultaneously, improving overall efficiency and accuracy.\nMeta-learning: Developing algorithms that can learn how to learn, enabling more efficient and effective learning on new tasks.\nContinual learning: Investigating techniques for deep learning models to learn continuously over time, without forgetting previous knowledge.\nDomain adaptation: Developing methods for adapting deep learning models trained on one domain to perform well on a different domain.\nAttention mechanisms: Exploring attention-based models that focus on important parts of the input, allowing for better performance on complex tasks.\nGraph neural networks: Developing deep learning models that can operate on graph-structured data, such as social networks or chemical compounds.\nActive learning: Investigating methods for training deep learning models with the most informative data samples, allowing for more efficient use of resources.\nGenerative models: Studying deep learning models that can generate new data samples, such as images, audio, or text.\nFew-shot learning: Developing deep learning models that can learn from just a few examples, enabling faster adaptation to new tasks or domains.\nLarge-scale deployment: Investigating techniques for deploying deep learning models at scale, in order to serve millions or billions of users with high performance and reliability.\n…"
  },
  {
    "objectID": "introduction_to_deep_learning.html#implementation-overview",
    "href": "introduction_to_deep_learning.html#implementation-overview",
    "title": "Introduction to Deep Learning (DL)",
    "section": "Implementation (Overview)",
    "text": "Implementation (Overview)\n\nData collection: The first step is to gather the data that will be used to train the machine learning algorithm.\nData preprocessing: The collected data needs to be cleaned, transformed, and prepared for the machine learning algorithm. This step includes tasks such as removing irrelevant or redundant data, handling missing values, and scaling the features.\nModel selection: The next step is to select a machine learning model that is appropriate for the task at hand.\nModel training: In this step, the selected machine learning model is trained on the preprocessed data. The goal is to find the optimal parameters that minimize the error between the predicted outputs and the actual outputs.\nModel evaluation: Once the machine learning model is trained, it needs to be evaluated to measure its performance on new, unseen data.\nModel application: Finally, the machine learning model can be deployed in a real-world environment where it can be used to make predictions or decisions."
  },
  {
    "objectID": "introduction_to_deep_learning.html#implementation-technical-level",
    "href": "introduction_to_deep_learning.html#implementation-technical-level",
    "title": "Introduction to Deep Learning (DL)",
    "section": "Implementation (Technical level)",
    "text": "Implementation (Technical level)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\n# Set random seed for reproducibility\ntorch.manual_seed(0)\n\n# Define some parameters\nbatch_size = 32\nnum_workers = 4\nlr = 0.001\nnum_epochs = 10\n# Define data transforms\ndata_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n# Load ImageNet dataset\ntrain_dataset = datasets.ImageFolder('/path/to/imagenet/train', transform=data_transforms)\nval_dataset = datasets.ImageFolder('/path/to/imagenet/val', transform=data_transforms)\n\n# Create data loaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n# Load pre-trained ResNet-18 model\nmodel = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n\n# Freeze all layers except the final classifier\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.fc.requires_grad = True\n\n# Replace final classifier with our own\nmodel.fc = nn.Linear(512, 1000)\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.fc.parameters(), lr=lr, momentum=0.9)\n# Train model\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    train_acc = 0.0\n    val_loss = 0.0\n    val_acc = 0.0\n\n    # Train on training set\n    model.train()\n    for i, (images, labels) in enumerate(train_loader):\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # Compute training accuracy\n        _, preds = torch.max(outputs, 1)\n        train_acc += torch.sum(preds == labels.data)\n        train_loss += loss.item() * images.size(0)\n\n    train_loss /= len(train_loader.dataset)\n    train_acc = train_acc.double() / len(train_loader.dataset)\n\n    # Evaluate on validation set\n    model.eval()\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(val_loader):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Compute validation accuracy\n            _, preds = torch.max(outputs, 1)\n            val_acc += torch.sum(preds == labels.data)\n            val_loss += loss.item() * images.size(0)\n\n        val_loss /= len(val_loader.dataset)\n        val_acc = val_acc.double() / len(val_loader.dataset)\n\n    # Print epoch results\n    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')"
  },
  {
    "objectID": "installation-guide.html",
    "href": "installation-guide.html",
    "title": "Installation guide",
    "section": "",
    "text": "This part of the summer school uses the Python programming language throughout the sessions. In case you are not familiar with Python it will still be possible to run code or get familiar with general concepts. Using python is necessary because modern deep learning libraries like PyTorch are the de facto standard, which becomes relevant for workshop session 2 and 3."
  },
  {
    "objectID": "installation-guide.html#session-1",
    "href": "installation-guide.html#session-1",
    "title": "Installation guide",
    "section": "Session 1",
    "text": "Session 1\nPlease make sure to have a working installation of miniconda, which includes an up-tp-date version of python. You can the version for your operating system of choice from: https://docs.conda.io/en/latest/miniconda.html\nIf you have miniconda installed, please setup a conda environment. The following setup instructions are valid for MacOS or Linux, in case of Windows look for the Anaconda Prompt Terminal, use Windows-Subsystem for Linux (WSL), or checkout the https://docs.conda.io/en/latest/index.html webiste for further help.\nAfter installing miniconda you and have opened a Terminal we create the environment as follows:\n\nconda create -n workshop-kenya\nconda activate workshop-kenya\n\nNow that the environment is active you can install all the necessary python packages. You don’t need to install everything at once but can do so through-out the workshop. Please make sure to always activate the conda environemnt before installing anything python-related with pip, conda or mamba.\nTo start with some installions:\n\npip install jupyterlab numpy pandas matplotlib seaborn msprime scikit-allel tsinfer numba tsdate\n\nIf you have finished working you may simply close the terminal or type conda deactivate."
  },
  {
    "objectID": "installation-guide.html#session-2",
    "href": "installation-guide.html#session-2",
    "title": "Installation guide",
    "section": "Session 2",
    "text": "Session 2\nSome installations are a bit more complicated like the installtions for the deep learning library and graph neural network extension:\nLet’s first install mamba following the websites instructions: https://mamba.readthedocs.io/en/latest/installation.html\n\nconda install mamba -n base -c conda-forge\n\nInstalling mamba is not strictly necessary since conda is already installed but it will make the following installations faster. You may use “conda” and “mamba” interchangingly.\nNext go to the Pytorch website (https://pytorch.org/) and copy the relevant installation command for you:\nFor example:\n> mamba install pytorch torchvision pytorch-cuda=11.6 -c pytorch -c nvidia"
  },
  {
    "objectID": "installation-guide.html#session-3",
    "href": "installation-guide.html#session-3",
    "title": "Installation guide",
    "section": "Session 3",
    "text": "Session 3\nInstallation of Pytorch Geometric. Please go to the Pytorch Geometric website (https://pytorch-geometric.readthedocs.io/) and follow the installation instructions:\nFor example:\n\nmamba install pyg -c pyg"
  },
  {
    "objectID": "session_1_example.html",
    "href": "session_1_example.html",
    "title": "1. Session (shortened)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport allel\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "session_1_example.html#dhfr-gene",
    "href": "session_1_example.html#dhfr-gene",
    "title": "1. Session (shortened)",
    "section": "DHFR gene",
    "text": "DHFR gene"
  },
  {
    "objectID": "session_1_example.html#loading-and-filtering-the-metadata-file",
    "href": "session_1_example.html#loading-and-filtering-the-metadata-file",
    "title": "1. Session (shortened)",
    "section": "Loading and filtering the metadata file",
    "text": "Loading and filtering the metadata file\n\nsamples_path = \"/home/kevinkorfmann/Projects/malaria/data/Pf7_samples.txt\"\nsamples_metadata = pd.read_csv(samples_path, sep=\"\\t\")\n\nafrican_subset = ['Kenya', 'Ethiopia', 'Tanzania'] # 'Ethiopia', 'Tanzania', 'Uganda'\n\n# form sample table above create mask to filter the table to only contain rows of interest\nsamples_metadata_mask = [True if criteria in african_subset else False for criteria in samples_metadata.Country]\nsamples_metadata = samples_metadata[samples_metadata_mask]\n\n# quality control filtering\n#samples_metadata = samples_metadata[samples_metadata[\"QC pass\"]]\n\n# we only look at genomic DNA (gDNA) for now\n#samples_metadata_mask = [True if criteria in [\"gDNA\"] else False for criteria in samples_metadata[\"Sample type\"]]\n#samples_metadata = samples_metadata[samples_metadata_mask]\n\n# reseting tables indices\n#samples_metadata = samples_metadata.reset_index(drop=True)\n\n\nnp.unique(samples_metadata.Country.tolist())\n\narray(['Bangladesh', 'Benin', 'Burkina Faso', 'Cambodia', 'Cameroon',\n       'Colombia', \"Côte d'Ivoire\", 'Democratic Republic of the Congo',\n       'Ethiopia', 'Gabon', 'Gambia', 'Ghana', 'Guinea', 'India',\n       'Indonesia', 'Kenya', 'Laos', 'Madagascar', 'Malawi', 'Mali',\n       'Mauritania', 'Mozambique', 'Myanmar', 'Nigeria',\n       'Papua New Guinea', 'Peru', 'Senegal', 'Sudan', 'Tanzania',\n       'Thailand', 'Uganda', 'Venezuela', 'Vietnam', 'nan'], dtype='<U32')"
  },
  {
    "objectID": "session_1_example.html#loading-the-vcf-file",
    "href": "session_1_example.html#loading-the-vcf-file",
    "title": "1. Session (shortened)",
    "section": "Loading the VCF file",
    "text": "Loading the VCF file\n\nvcf_file = str(\"../../datasets/malaria-chromosomes/DHFR-TS_surrounding_region.vcf.gz\")\ncallset = allel.read_vcf(vcf_file, fields=['samples', 'calldata/GT', 'variants/ALT', 'variants/CHROM',\n                                            'variants/FILTER_PASS', 'variants/ID', 'variants/POS',\n                                            'variants/QUAL', 'variants/REF','calldata/GT','calldata/PS'])\n\ngt = allel.GenotypeArray(callset['calldata/GT'])\nphase_sets = callset['calldata/PS']\npos = callset[\"variants/POS\"]"
  },
  {
    "objectID": "session_1_example.html#filtering-the-genotypes",
    "href": "session_1_example.html#filtering-the-genotypes",
    "title": "1. Session (shortened)",
    "section": "Filtering the Genotypes",
    "text": "Filtering the Genotypes\n\ndef get_genotypes(samples, genotypes):\n    mask = [True if sample in samples else False for sample in callset[\"samples\"]]\n    genotypes = genotypes[:,mask]\n    gt_np = np.array(genotypes.to_haplotypes())\n    return gt_np\n\nsamples_id = samples_metadata.Sample.tolist()\ngt_samples = get_genotypes(samples_id, gt)\n\n\ngt_samples\n\narray([[ 0,  0,  0, ...,  0,  0,  0],\n       [ 1,  1,  1, ...,  1,  0,  1],\n       [ 0,  0,  0, ...,  0,  0,  0],\n       ...,\n       [-1, -1,  0, ...,  1,  0,  1],\n       [ 0,  0,  0, ...,  0,  0,  0],\n       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int8)"
  },
  {
    "objectID": "session_1_example.html#calculating-the-statistic-and-plotting",
    "href": "session_1_example.html#calculating-the-statistic-and-plotting",
    "title": "1. Session (shortened)",
    "section": "Calculating the statistic and plotting",
    "text": "Calculating the statistic and plotting\n\nac = gt_samples\npi, windows, n_bases_sen, counts_sen = allel.windowed_diversity(pos=pos, ac=ac, size=10_000, start=pos[0])\nwindow_start = pd.DataFrame(windows)[0]\nsns.lineplot(x=window_start, y=pi, label=\"Nucleotide Diversity\")\n\nplt.axvline(747897, ls='--')\nplt.axvline(750065, ls='--')\nplt.grid(True)\n\n/opt/miniconda3/envs/workshop-kenya/lib/python3.10/site-packages/allel/stats/diversity.py:99: RuntimeWarning: divide by zero encountered in divide\n  mpd = np.where(n_pairs > 0, n_diff / n_pairs, fill)"
  },
  {
    "objectID": "session_1_example.html#mdr-1-gene",
    "href": "session_1_example.html#mdr-1-gene",
    "title": "1. Session (shortened)",
    "section": "MDR 1 gene",
    "text": "MDR 1 gene\n\nimport pandas as pd\nimport numpy as np\nimport allel\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "session_1_example.html#loading-and-filtering-the-metadata-file-1",
    "href": "session_1_example.html#loading-and-filtering-the-metadata-file-1",
    "title": "1. Session (shortened)",
    "section": "Loading and filtering the metadata file",
    "text": "Loading and filtering the metadata file\n\nsamples_path = \"/home/kevinkorfmann/Projects/malaria/data/Pf7_samples.txt\"\nsamples_metadata = pd.read_csv(samples_path, sep=\"\\t\")\n\nafrican_subset = ['Kenya'] # 'Ethiopia', 'Tanzania', 'Uganda'\n\n# form sample table above create mask to filter the table to only contain rows of interest\nsamples_metadata_mask = [True if criteria in african_subset else False for criteria in samples_metadata.Country]\nsamples_metadata = samples_metadata[samples_metadata_mask]\n\n# quality control filtering\nsamples_metadata = samples_metadata[samples_metadata[\"QC pass\"]]\n\n# we only look at genomic DNA (gDNA) for now\nsamples_metadata_mask = [True if criteria in [\"gDNA\"] else False for criteria in samples_metadata[\"Sample type\"]]\nsamples_metadata = samples_metadata[samples_metadata_mask]\n\n# reseting tables indices\nsamples_metadata = samples_metadata.reset_index(drop=True)"
  },
  {
    "objectID": "session_1_example.html#loading-the-vcf-file-1",
    "href": "session_1_example.html#loading-the-vcf-file-1",
    "title": "1. Session (shortened)",
    "section": "Loading the VCF file",
    "text": "Loading the VCF file\n\nvcf_file = str(\"../../datasets/malaria-chromosomes/MDR1_surrounding_region.vcf.gz\")\ncallset = allel.read_vcf(vcf_file, fields=['samples', 'calldata/GT', 'variants/ALT', 'variants/CHROM',\n                                            'variants/FILTER_PASS', 'variants/ID', 'variants/POS',\n                                            'variants/QUAL', 'variants/REF','calldata/GT','calldata/PS'])\n\ngt = allel.GenotypeArray(callset['calldata/GT'])\nphase_sets = callset['calldata/PS']\npos = callset[\"variants/POS\"]"
  },
  {
    "objectID": "session_1_example.html#filtering-the-genotypes-1",
    "href": "session_1_example.html#filtering-the-genotypes-1",
    "title": "1. Session (shortened)",
    "section": "Filtering the Genotypes",
    "text": "Filtering the Genotypes\n\ndef get_genotypes(samples, genotypes):\n    mask = [True if sample in samples else False for sample in callset[\"samples\"]]\n    genotypes = genotypes[:,mask]\n    gt_np = np.array(genotypes.to_haplotypes())\n    return gt_np\n\nsamples_id = samples_metadata.Sample.tolist()\ngt_samples = get_genotypes(samples_id, gt)"
  },
  {
    "objectID": "session_1_example.html#calculating-the-statistic-and-plotting-1",
    "href": "session_1_example.html#calculating-the-statistic-and-plotting-1",
    "title": "1. Session (shortened)",
    "section": "Calculating the statistic and plotting",
    "text": "Calculating the statistic and plotting\n\nac = gt_samples\npi, windows, n_bases_sen, counts_sen = allel.windowed_diversity(pos=pos, ac=ac, size=10_000, start=pos[0])\nwindow_start = pd.DataFrame(windows)[0]\nsns.lineplot(x=window_start, y=pi, label=\"Nucleotide Diversity\")\n\nplt.axvline(955955, ls='--')\nplt.axvline(963095, ls='--')\nplt.grid(True)\n\n/opt/miniconda3/envs/workshop-kenya/lib/python3.10/site-packages/allel/stats/diversity.py:99: RuntimeWarning: divide by zero encountered in divide\n  mpd = np.where(n_pairs > 0, n_diff / n_pairs, fill)"
  },
  {
    "objectID": "session_3.html",
    "href": "session_3.html",
    "title": "3. Session - Training and Inference of Coalescent Models",
    "section": "",
    "text": "In the last session, we’ll be using what have learned about neural networks, but use a different architecture/model, suitable for processing of graphs.\nGraph Neural Networks (GNNs) are a relatively new and exciting area of research in the field of deep learning. GNNs are designed to operate on graph-structured data, where the input data is represented as a graph, consisting of nodes and edges. GNNs have shown great potential in various fields such as social network analysis, molecule structure prediction, and recommender systems.\nOne of the core components of GNNs is the graph convolution operation. Unlike regular convolutions, which operate on fixed grid-like structures such as images, graph convolutions operate on irregular graph structures. Graph convolutions aim to propagate information between nodes in a graph, taking into account the graph structure.\nThe key difference between graph convolutions and regular convolutions is that graph convolutions use learnable weights, which are applied to the neighborhood of each node, rather than applying the same weights to all nodes in a fixed grid. This allows the model to learn node representations that capture the graph structure, which can be used for various downstream tasks.\nSome common tasks that GNNs are used for include:\nOverall, GNNs and graph convolutions represent a promising approach for dealing with graph-structured data, and have the potential to revolutionize a wide range of applications in the future."
  },
  {
    "objectID": "session_3.html#background---args-msprime-tsinfer-tsdate",
    "href": "session_3.html#background---args-msprime-tsinfer-tsdate",
    "title": "3. Session - Training and Inference of Coalescent Models",
    "section": "3.0 Background - ARGs, msprime, tsinfer, tsdate",
    "text": "3.0 Background - ARGs, msprime, tsinfer, tsdate\nAncestral recombination graphs (ARGs) are probabilistic models that represent the history of genetic variation within a population over time. They capture the patterns of genetic inheritance and recombination that occur in populations, and can be used to simulate genetic data, infer evolutionary histories, and estimate population parameters.\nThe software package msprime is a popular tool for simulating ARGs under a variety of demographic scenarios. msprime uses a coalescent simulation framework, which models the process by which lineages coalesce over time, to generate ARGs that reflect the demographic history of a population.\nOnce an ARG is generated, it can be analyzed using tools such as tskit, which is a Python library for working with large-scale genomic data. tskit provides efficient data structures and algorithms for manipulating ARGs, and can be used for tasks such as simulating genetic data, estimating demographic parameters, and inferring evolutionary histories.\nAnother important tool for working with ARGs is tsinfer, which is a method for inferring ARGs directly from genotype data. tsinfer uses a probabilistic approach to estimate the most likely ARG that is consistent with the observed genetic data. This can be useful for reconstructing the evolutionary history of a population, or for identifying regions of the genome that have been subject to natural selection.\nFinally, tsdate is a method for estimating the timescale of evolutionary events in an ARG. tsdate uses a machine learning approach to estimate the mutation rate and time to the most recent common ancestor (TMRCA) for each branch in the ARG. This information can be used to date the evolutionary events that are represented in the ARG, such as the time of a population split or the onset of a selective sweep.\nOverall, ARGs and the tools for working with them represent a powerful framework for studying the evolutionary history of populations and the genetic variation that underlies it. These tools are increasingly being used in fields such as population genetics, evolutionary biology, and human genetics, and are likely to play an important role in future research in these areas."
  },
  {
    "objectID": "session_3.html#simulation-of-args-under-the-beta-coalescent",
    "href": "session_3.html#simulation-of-args-under-the-beta-coalescent",
    "title": "3. Session - Training and Inference of Coalescent Models",
    "section": "3.1 Simulation of ARGs under the Beta-coalescent",
    "text": "3.1 Simulation of ARGs under the Beta-coalescent"
  }
]